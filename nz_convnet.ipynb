{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "da854b15-3d24-4a36-b3ed-3d488835cb2c",
    "_uuid": "bb9a5222d826d11f6ed4367e6e2b4b4a3d5a1edb"
   },
   "source": [
    "# Part 0 - Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3a0302dcf95e8b5ba2aff2b600bcebbac86f10ea"
   },
   "outputs": [],
   "source": [
    "# Set number of GPUs\n",
    "num_gpus = 4   #defaults to 1 if one-GPU or one-CPU. If 4 GPUs, set to 4.\n",
    "\n",
    "# Set height (y-axis length) and width (x-axis length) to train model on\n",
    "img_height, img_width = (256,256)  #Default to (256,266), use (None,None) if you do not want to resize imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "66a77cab-abe1-44cf-9276-d1b32187cea5",
    "_uuid": "5dabd530b1d74b3275721cc981311f39d6728b18"
   },
   "outputs": [],
   "source": [
    "# Import all the necessary libraries\n",
    "import os\n",
    "import datetime\n",
    "import glob\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io                                     #Used for imshow function\n",
    "import skimage.transform                              #Used for resize function\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Conv2DTranspose\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, Lambda, AlphaDropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import load_model, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import multi_gpu_model, plot_model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import ogr\n",
    "import gdal\n",
    "\n",
    "print('Python       :', sys.version.split('\\n')[0])\n",
    "print('Numpy        :', np.__version__)\n",
    "print('Skimage      :', skimage.__version__)\n",
    "print('Scikit-learn :', sklearn.__version__)\n",
    "print('Keras        :', keras.__version__)\n",
    "print('Tensorflow   :', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1bdba649abfdf285b68181bc05be11088ec2e7dd"
   },
   "outputs": [],
   "source": [
    "# Set seed values\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1083fdfe-2505-412f-8291-89b6307e2e2d",
    "_uuid": "5c645d5dc179f8aa640021f4a2306cb65873c4b6"
   },
   "outputs": [],
   "source": [
    "# Have a look at our data folder\n",
    "topDir = os.getcwd()+\"/data\"  #default top directory\n",
    "os.chdir(topDir)\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "23b9e37c-8250-439c-b50b-3a4ddc652c3a",
    "_uuid": "a1951e5b2626c7460dda35724fc5503092b89cf9"
   },
   "source": [
    "# Part 1 - Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pcjericks.github.io/py-gdalogr-cookbook/raster_layers.html\n",
    "# https://gis.stackexchange.com/questions/16837/how-can-i-turn-a-shapefile-into-a-mask-and-calculate-the-mean\n",
    "def vectorPoly_to_rasterMask(vector, raster, output, show=False):\n",
    "    \"\"\"\n",
    "    Function to turn a vector Polygon (ogr) into a raster binary mask (gdal) of 1 for present, 0 for absent\n",
    "    \n",
    "    Outputs a raster geotiff with extents according to the input raster.\n",
    "    \"\"\"\n",
    "    ## Open raster data source\n",
    "    assert(os.path.exists(raster))\n",
    "    raster_ds = gdal.Open(raster)\n",
    "    raster_prj = raster_ds.GetProjection()\n",
    "    \n",
    "    ulx, px, rx, uly, ry, py = raster_ds.GetGeoTransform()  #upper left X, pixel resolution X, rotation X, upper left Y, pixel resolution Y, rotation Y\n",
    "    px, py = round(px,3), round(py,2)  #round pixel size to two decimal places\n",
    "    width, height = raster_ds.RasterXSize, raster_ds.RasterYSize  #number of x columns and number of y rows\n",
    "    #print(ulx, px, rx, uly, ry, py), (width, height)\n",
    "    '''\n",
    "\n",
    "      ul-------ur\n",
    "    ^  |       |\n",
    "    |  |  geo  |    y increases going up, x increases going right\n",
    "    y  |       |\n",
    "      ll-------lr\n",
    "          x-->\n",
    "\n",
    "    '''\n",
    "    assert(rx==0 and ry==0)   #assuming zero rotation!!\n",
    "    llx = ulx\n",
    "    lly = uly + (height * py)\n",
    "    urx = ulx + (width * px)\n",
    "    ury = uly\n",
    "    bbox = (llx, lly, urx, ury)  #minx, miny, maxx, maxy\n",
    "    print(\"min_xy:({0},{1}), max_xy:({2},{3})\".format(*bbox))\n",
    "    \n",
    "    \n",
    "    ## Open vector data source\n",
    "    assert(os.path.exists(vector))\n",
    "    vector_ds = ogr.Open(vector)\n",
    "    vector_lyr = vector_ds.GetLayer()\n",
    "    vector_prj = vector_lyr.GetSpatialRef()\n",
    "    vector_ext = vector_lyr.GetExtent()   #x_min, x_max, y_min, y_max\n",
    "    #print(vector_ext)\n",
    "    \n",
    "    \n",
    "    ## Create the raster mask according to input raster dimensions\n",
    "    x_res = int((urx - llx) / px)\n",
    "    y_res = int((ury - lly) / abs(py))  #turn negative pixel size y to absolute value\n",
    "    #print(x_res, y_res)\n",
    "    target_ds = gdal.GetDriverByName('GTiff').Create(output, x_res, y_res, 1, gdal.GDT_Byte)\n",
    "    target_ds.SetGeoTransform((llx, px, rx, uly, ry, py))\n",
    "    target_ds.SetProjection(raster_prj)\n",
    "    band = target_ds.GetRasterBand(1)\n",
    "    band.SetNoDataValue(np.nan)\n",
    "    \n",
    "    ## Rasterize\n",
    "    err = gdal.RasterizeLayer(target_ds, [1], vector_lyr, None, None, [1], ['ALL_TOUCHED=TRUE'])\n",
    "    target_ds.FlushCache()\n",
    "    \n",
    "    \n",
    "    ## Create output arrays\n",
    "    img_ary = np.dstack([raster_ds.GetRasterBand(i).ReadAsArray() for i in range(1,4)])\n",
    "    msk_ary = target_ds.GetRasterBand(1).ReadAsArray()\n",
    "   \n",
    "    \n",
    "    ## Visualize the raster with its output mask\n",
    "    if show==True:\n",
    "        #f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "        skimage.io.imshow(img_ary)\n",
    "        plt.show()\n",
    "        skimage.io.imshow(msk_ary)\n",
    "        plt.show()\n",
    "        #skimage.io.imsave(output, mask_ary)\n",
    "    \n",
    "    ## Final checks and turn mask into boolean array\n",
    "    assert(img_ary.shape[:2]==msk_ary.shape)   #check that shape of image and mask are the same\n",
    "    msk_ary = skimage.transform.resize(msk_ary, output_shape=msk_ary.shape+(1,), mode='constant', preserve_range=True)  #need to add an extra dimension so mask.shape = (img_height, img_width, 1)\n",
    "    msk_ary = msk_ary.astype(bool)  #convert to binary mask of either 0 or 1\n",
    "    \n",
    "    return img_ary, msk_ary\n",
    "\n",
    "if not os.path.exists('X_train.npy') or not os.path.exists('Y_train.npy'):\n",
    "    img_ary, msk_ary = vectorPoly_to_rasterMask(vector='nz-building-outlines-pilot.shp', raster='RGB_BX24_5K_0401.tif', output='tmp_mask.tif')\n",
    "    print(img_ary.shape, img_ary.dtype)\n",
    "    print(msk_ary.shape, msk_ary.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('X_train.npy') or not os.path.exists('Y_train.npy'):\n",
    "    X_ary = img_ary\n",
    "    Y_ary = msk_ary\n",
    "    X_ary_list = []\n",
    "    Y_ary_list = []\n",
    "\n",
    "    for x_step in range(0, X_ary.shape[0], img_width):\n",
    "        for y_step in range(0, X_ary.shape[1], img_height):\n",
    "            x0, x1 = x_step, x_step+img_width\n",
    "            y0, y1 = y_step, y_step+img_height\n",
    "            #print(x0, x1, y0, y1)\n",
    "            crop_X_ary = X_ary[y0:y1, x0:x1]\n",
    "            crop_Y_ary = Y_ary[y0:y1, x0:x1]\n",
    "            try:\n",
    "                assert(crop_X_ary.shape == (img_height, img_width, 3))  #do not include images not matching the intended size\n",
    "                assert(np.any(crop_Y_ary) == True)          #do not include images without a mask\n",
    "            except AssertionError:\n",
    "                #print(crop_X_ary.shape)\n",
    "                continue\n",
    "            X_ary_list.append(crop_X_ary)\n",
    "            Y_ary_list.append(crop_Y_ary)\n",
    "    X_train = np.stack(X_ary_list)\n",
    "    Y_train = np.stack(Y_ary_list)\n",
    "    print(X_train.shape)\n",
    "    np.save('X_train.npy', X_train)\n",
    "    np.save('Y_train.npy', Y_train)\n",
    "elif os.path.exists('X_train.npy') and os.path.exists('Y_train.npy'):\n",
    "    X_train = np.load('X_train.npy')\n",
    "    Y_train = np.load('Y_train.npy')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_train.dtype)\n",
    "print(Y_train.shape, Y_train.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7cf01d39c5565b48eaba6a2be42518ca7ff02341"
   },
   "source": [
    "## Visualize masks on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a2e8483a7b4c4bb5324340ac04434e395f84c793",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "id = 128\n",
    "print(X_train[id].shape)\n",
    "skimage.io.imshow(X_train[id])\n",
    "plt.show()\n",
    "skimage.io.imshow(Y_train[id][:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7129b20c-bdc2-43a5-8764-a762e2bf79b2",
    "_uuid": "0a50c27113c940bd20e527edc422143ba4f8a9e1"
   },
   "source": [
    "# Part 2 - Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "07663a1d6c70143c02c78cdacaeb58f21e835dc0"
   },
   "outputs": [],
   "source": [
    "# Custom IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.50, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1d4cdf5b-be18-4abf-86ef-d76e8294474c",
    "_uuid": "6f9a58dd35b6aa0d43b4bd4dd89b25f52a4ab74f"
   },
   "outputs": [],
   "source": [
    "# Design our model architecture here\n",
    "def keras_model(img_width=256, img_height=256):\n",
    "    '''\n",
    "    Modified from https://keunwoochoi.wordpress.com/2017/10/11/u-net-on-keras-2-0/\n",
    "    Architecture inspired by https://blog.deepsense.ai/deep-learning-for-satellite-imagery-via-image-segmentation/\n",
    "    '''\n",
    "    #n_ch_exps = [4, 5, 6, 7, 8]   #the n-th deep channel's exponent i.e. 2**n 16,32,64,128,256\n",
    "    n_ch_exps = [6, 6, 6, 6, 6]\n",
    "    k_size = (3, 3)                     #size of filter kernel\n",
    "    k_init = 'lecun_normal'             #kernel initializer\n",
    "    activation = 'selu'\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        ch_axis = 1\n",
    "        input_shape = (3, img_width, img_height)\n",
    "    elif K.image_data_format() == 'channels_last':\n",
    "        ch_axis = 3\n",
    "        input_shape = (img_width, img_height, 3)\n",
    "\n",
    "    inp = Input(shape=input_shape)\n",
    "    tf.summary.image(name='input', tensor=inp)\n",
    "    encodeds = []\n",
    "\n",
    "    # encoder\n",
    "    enc = inp\n",
    "    print(n_ch_exps)\n",
    "    for l_idx, n_ch in enumerate(n_ch_exps):\n",
    "        with K.name_scope('Encode_block_'+str(l_idx)):\n",
    "            enc = Conv2D(filters=2**n_ch, kernel_size=k_size, activation=activation, padding='same', kernel_initializer=k_init)(enc)\n",
    "            enc = AlphaDropout(0.1*l_idx,)(enc)\n",
    "            enc = Conv2D(filters=2**n_ch, kernel_size=k_size, dilation_rate=(2,2), activation=activation, padding='same', kernel_initializer=k_init)(enc)\n",
    "            encodeds.append(enc)\n",
    "            #print(l_idx, enc)\n",
    "            if l_idx < len(n_ch_exps)-1:  #do not run max pooling on the last encoding/downsampling step\n",
    "                enc = MaxPooling2D(pool_size=(2,2))(enc)  #strides = pool_size if strides is not set\n",
    "                #enc = Conv2D(filters=2**n_ch, kernel_size=k_size, strides=(2,2), activation=activation, padding='same', kernel_initializer=k_init)(enc)\n",
    "            tf.summary.histogram(\"conv_encoder\", enc)\n",
    "            \n",
    "    # decoder\n",
    "    dec = enc\n",
    "    print(n_ch_exps[::-1][1:])\n",
    "    decoder_n_chs = n_ch_exps[::-1][1:]\n",
    "    for l_idx, n_ch in enumerate(decoder_n_chs):\n",
    "        with K.name_scope('Decode_block_'+str(l_idx)):\n",
    "            l_idx_rev = len(n_ch_exps) - l_idx - 1  #\n",
    "            dec = concatenate([dec, encodeds[l_idx_rev]], axis=ch_axis)\n",
    "            dec = Conv2D(filters=2**n_ch, kernel_size=k_size, dilation_rate=(2,2), activation=activation, padding='same', kernel_initializer=k_init)(dec)\n",
    "            dec = AlphaDropout(0.1*l_idx)(dec)\n",
    "            dec = Conv2D(filters=2**n_ch, kernel_size=k_size, activation=activation, padding='same', kernel_initializer=k_init)(dec)\n",
    "            dec = Conv2DTranspose(filters=2**n_ch, kernel_size=k_size, strides=(2,2), activation=activation, padding='same', kernel_initializer=k_init)(dec)\n",
    "\n",
    "    outp = Conv2DTranspose(filters=1, kernel_size=k_size, activation='sigmoid', padding='same', kernel_initializer='glorot_normal')(dec)\n",
    "    tf.summary.image(name='output', tensor=outp)\n",
    "    \n",
    "    model = Model(inputs=[inp], outputs=[outp])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "30f3c231-d347-4d44-809a-ba5aa4d2944b",
    "_uuid": "796008f7760b64d768b201ae135e06ac9ce60007",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set some model compile parameters\n",
    "optimizer = keras.optimizers.Adam()\n",
    "loss      = 'binary_crossentropy'\n",
    "metrics   = [mean_iou]\n",
    "\n",
    "# Compile our model\n",
    "model = keras_model(img_width=img_width, img_height=img_height)\n",
    "model.summary()\n",
    "\n",
    "# For more GPUs\n",
    "if num_gpus > 1:\n",
    "    model = multi_gpu_model(model, gpus=num_gpus)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "05e830e6-c323-4c39-a707-e52a1c17957b",
    "_uuid": "3ef3e0dfd1e2e22c43c9a880a7e9e77473929ab7"
   },
   "source": [
    "# Part 3 - Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d78cd8da-0905-46e4-b969-37096272e00a",
    "_uuid": "7a0fbed34c6b95d6b2abd081b7838f9194af0c95"
   },
   "outputs": [],
   "source": [
    "# Runtime custom callbacks\n",
    "#%% https://github.com/deepsense-ai/intel-ai-webinar-neural-networks/blob/master/live_loss_plot.py\n",
    "# Fixed code to enable non-flat loss plots on keras model.fit_generator()\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import Callback\n",
    "from IPython.display import clear_output\n",
    "#from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "def translate_metric(x):\n",
    "    translations = {'acc': \"Accuracy\", 'loss': \"Log-loss (cost function)\"}\n",
    "    if x in translations:\n",
    "        return translations[x]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "class PlotLosses(Callback):\n",
    "    def __init__(self, figsize=None):\n",
    "        super(PlotLosses, self).__init__()\n",
    "        self.figsize = figsize\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "\n",
    "        self.base_metrics = [metric for metric in self.params['metrics'] if not metric.startswith('val_')]\n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(logs.copy())\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=self.figsize)\n",
    "        \n",
    "        for metric_id, metric in enumerate(self.base_metrics):\n",
    "            plt.subplot(1, len(self.base_metrics), metric_id + 1)\n",
    "            \n",
    "            plt.plot(range(1, len(self.logs) + 1),\n",
    "                     [log[metric] for log in self.logs],\n",
    "                     label=\"training\")\n",
    "            if self.params['do_validation']:\n",
    "                plt.plot(range(1, len(self.logs) + 1),\n",
    "                         [log['val_' + metric] for log in self.logs],\n",
    "                         label=\"validation\")\n",
    "            plt.title(translate_metric(metric))\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend(loc='center left')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show();\n",
    "\n",
    "plot_losses = PlotLosses(figsize=(16, 4))\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = 0.05\n",
    "X_data = X_train\n",
    "Y_data = Y_train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data,\n",
    "                                                    Y_data,\n",
    "                                                    train_size=1-validation_split,\n",
    "                                                    test_size=validation_split,\n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cec5a1ff-c983-426d-a0da-581f25966860",
    "_uuid": "b7b93a826a4b4337af83cf9999524035e7470601",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Finally train the model!!\n",
    "batch_size = 64\n",
    "\n",
    "#model.fit(x=X_train, y=Y_train, verbose=1, validation_split=0.14, batch_size=batch_size, epochs=250, callbacks=[plot_losses, tensorboard])\n",
    "model.fit(x=X_train, y=Y_train, verbose=1, validation_data=(X_test, Y_test), batch_size=batch_size, epochs=5, callbacks=[plot_losses, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save the model weights to a hdf5 file\n",
    "if num_gpus > 1:\n",
    "    #Refer to https://stackoverflow.com/questions/41342098/keras-load-checkpoint-weights-hdf5-generated-by-multiple-gpus\n",
    "    #model.summary()\n",
    "    model_out = model.layers[-2]  #get second last layer in multi_gpu_model i.e. model.get_layer('model_1')\n",
    "else:\n",
    "    model_out = model\n",
    "if not os.path.exists(topDir+\"/working\"):\n",
    "    os.makedirs(topDir+\"/working\")\n",
    "model_out.save_weights(filepath=topDir+\"/working/model-weights.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2cf8de83-1486-444d-9200-e1c2784b25cc",
    "_uuid": "d8b70e56c01002b673e354223a00df0c17b8cb83"
   },
   "source": [
    "# Part 4 - Evaluate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model\n",
    "model_loaded = keras_model(img_width=img_width, img_height=img_height)\n",
    "model_loaded.load_weights(topDir+\"/working/model-weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a78cd1cd-f47f-482a-bc7b-b1203beba9ac",
    "_uuid": "9179437a04bf2e63fc9f54d118bdd8840f30636a"
   },
   "outputs": [],
   "source": [
    "# Use model to predict test labels\n",
    "Y_hat_test = model_loaded.predict(X_test, verbose=1)\n",
    "print(Y_hat_test.shape, Y_hat_test.dtype)\n",
    "Y_hat_train = model_loaded.predict(X_train, verbose=1)\n",
    "print(Y_hat_train.shape, Y_hat_train.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictions on the cross-validation test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for id in range(len(Y_hat_test)):\n",
    "    try:\n",
    "        #id = random.randrange(0,len(Y_hat))\n",
    "        print(id, X_test[id].shape)\n",
    "        skimage.io.imshow(X_test[id])\n",
    "        plt.show()\n",
    "        skimage.io.imshow(Y_hat_test[id][:,:,0])\n",
    "        plt.show()\n",
    "        skimage.io.imshow(Y_test[id][:,:,0])\n",
    "        plt.show()\n",
    "    except TypeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictions on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    try:\n",
    "        id = random.randrange(0,len(Y_hat_train))\n",
    "        print(id, X_train[id].shape)\n",
    "        skimage.io.imshow(X_train[id])\n",
    "        plt.show()\n",
    "        skimage.io.imshow(Y_hat_train[id][:,:,0])\n",
    "        plt.show()\n",
    "        skimage.io.imshow(Y_train[id][:,:,0])\n",
    "        plt.show()\n",
    "    except TypeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictions on the new data!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiled list of bbox\n",
    "def ary_to_tiles(ary, shape=(256,256), exclude_empty=False):\n",
    "    \"\"\"\n",
    "    Function to turn a big 2D numpy array (image) and tile it into a set number of shapes\n",
    "    \n",
    "    Outputs a stacked numpy array suitable for input into a Convolutional Neural Network\n",
    "    \"\"\"\n",
    "    assert(isinstance(ary, np.ndarray))\n",
    "    assert(isinstance(shape, tuple))\n",
    "    \n",
    "    ary_height, ary_width = shape\n",
    "    ary_list = []\n",
    "    \n",
    "    for x_step in range(0, ary.shape[0], ary_width):\n",
    "        for y_step in range(0, ary.shape[1], ary_height):\n",
    "            x0, x1 = x_step, x_step+img_width\n",
    "            y0, y1 = y_step, y_step+img_height\n",
    "            \n",
    "            crop_ary = ary[y0:y1, x0:x1]\n",
    "            try:\n",
    "                assert(crop_ary.shape == (ary_height, ary_width, ary.shape[2]))  #do not include images not matching the intended size\n",
    "                if exclude_empty == True:\n",
    "                    assert(np.any(crop_ary) == True)          #do not include images without a mask\n",
    "            except AssertionError:\n",
    "                #print(crop_X_ary.shape)\n",
    "                continue\n",
    "            ary_list.append(crop_ary)\n",
    "    \n",
    "    return np.stack(ary_list)\n",
    "ds = gdal.Open('wellington-03m-rural-aerial-photos-2012-2013.tif') #get from https://data.linz.govt.nz/layer/51870-wellington-03m-rural-aerial-photos-2012-2013/   \n",
    "ary = np.dstack([ds.GetRasterBand(i).ReadAsArray() for i in range(1,4)])\n",
    "W_test = ary_to_tiles(ary, shape=(img_height, img_width))\n",
    "W_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_hat_test = model_loaded.predict(W_test, verbose=1)\n",
    "print(W_hat_test.shape, W_hat_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    try:\n",
    "        id = random.randrange(0,len(W_test))\n",
    "        print(id, X_train[id].shape)\n",
    "        skimage.io.imshow(W_test[id])\n",
    "        plt.show()\n",
    "        skimage.io.imshow(W_hat_test[id][:,:,0])\n",
    "        plt.show()\n",
    "        #skimage.io.imshow(Y_train[id][:,:,0])\n",
    "        #plt.show()\n",
    "    except TypeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "88938860-0dc9-4b99-bc53-292a0758a90a",
    "_uuid": "25f599e017681e4a269bfc2dc6640bfb4532e2ff"
   },
   "source": [
    "# Part 5 - Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
